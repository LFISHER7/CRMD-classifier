from __future__ import print_function
from hyperopt import Trials, STATUS_OK, tpe
from hyperas import optim
from hyperas.distributions import uniform
from keras import optimizers
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import np_utils
import numpy as np



def data():
    nb_classes = 13
    X_train = np.load('../Data_as_numpy/DENSE_MODEL/train.npy')
    y_train = np.load('../Data_as_numpy/DENSE_MODEL/train-label.npy')
    X_test = np.load('../Data_as_numpy/DENSE_MODEL/test.npy')
    y_test = np.load('../Data_as_numpy/DENSE_MODEL/test-label.npy')
    print('X_train shape:', X_train.shape)
    print('X_test shape:', X_test.shape)
    print(X_train.shape[0], 'train samples')
    print(X_test.shape[0], 'test samples')

    # convert class vectors to binary class matrices
    Y_train = np_utils.to_categorical(y_train, nb_classes)
    Y_test = np_utils.to_categorical(y_test, nb_classes)

    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    # this will do preprocessing and realtime data augmentation
    datagen = ImageDataGenerator(
        rotation_range=180,  # randomly rotate images in range
        width_shift_range=0.2,  # randomly shift images horizontally
        height_shift_range=0.2,  # randomly shift images vertically
        horizontal_flip=True)  # randomly flip images

    datagen.fit(X_train)

    return datagen, X_train, Y_train, X_test, Y_test


def model(datagen, X_train, Y_train, X_test, Y_test):
    batch_size = {{choice([16, 32])}}
    nb_epoch = 50

    model = Sequential()

    model.add(Convolution2D(64, (3, 3), padding='same', activation={{choice(['relu', 'sigmoid'])}},
                            input_shape=X_train.shape[1:]))
    model.add(Convolution2D(64, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Convolution2D(128, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(128, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Convolution2D(256, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(256, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(256, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))
    model.add(Convolution2D(512, (3, 3), padding='same', activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dropout({{uniform(0, 1)}}))
    model.add(Dense(13, activation='softmax'))
    # let's train the model using SGD + momentum (how original).
    adam = optimizers.Adam(lr={{uniform(0.01, 0.00001)}})
    # sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    model.compile(loss='categorical_crossentropy',
                  optimizer=adam,
                  # optimizer= {{choice(['Adam', 'SGD', 'RMSprop'])}},
                  metrics=['accuracy'])

    # fit the model on the batches generated by datagen.flow()
    model.fit_generator(datagen.flow(X_train, Y_train,
                        batch_size=batch_size),
                        samples_per_epoch=X_train.shape[0],
                        nb_epoch=nb_epoch,
                        validation_data=(X_test, Y_test),
                        verbose=1)

    score, acc = model.evaluate(X_test, Y_test, verbose=0)


    return {'loss': -acc, 'status': STATUS_OK, 'model': model}


if __name__ == '__main__':

    datagen, X_train, Y_train, X_test, Y_test = data()

    best_run, best_model = optim.minimize(model=model,
                                          data=data,
                                          algo=tpe.suggest,
                                          max_evals=2,
                                          trials=Trials())


    print("Evalutation of best performing model:")
    print(best_model.evaluate(X_test, Y_test))
    print("Best performing model chosen hyper-parameters:")
    print(best_run)
